{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ConvNet import ConvNet \n",
    "import argparse\n",
    "import numpy as np     \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device selected:  cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if cuda is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Set proper device based on cuda availability \n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Torch device selected: \", device)\n",
    "\n",
    "# Create transformations to apply to each data sample \n",
    "# Can specify variations such as image flip, color flip, random crop, ...\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "# Load datasets for training and testing\n",
    "# Inbuilt datasets available in torchvision (check documentation online)\n",
    "dataset1 = datasets.MNIST('./data/', train=True, download=True,\n",
    "                    transform=transform)\n",
    "dataset2 = datasets.MNIST('./data/', train=False,\n",
    "                    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=10, num_workers=4):\n",
    "    train_loader = DataLoader(dataset1, batch_size = batch_size, \n",
    "                            shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(dataset2, batch_size = batch_size, \n",
    "                                shuffle=False, num_workers=4)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "def plot(num_epochs, train_losses, train_accuracies, save=0, mode=1):\n",
    "    x = range(1, num_epochs+1)\n",
    "\n",
    "    plt.plot(x, train_losses)\n",
    "    plt.plot(x, train_accuracies)\n",
    "    plt.legend(['Train Loss', 'Train Accuracy'])\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'plots/model_{mode}.jpg')\n",
    "        plt.show()\n",
    "\n",
    "def train(model, device, train_loader, optimizer, criterion, epoch, batch_size, num_epochs):\n",
    "    '''\n",
    "    Trains the model for an epoch and optimizes it.\n",
    "    model: The model to train. Should already be in correct device.\n",
    "    device: 'cuda' or 'cpu'.\n",
    "    train_loader: dataloader for training samples.\n",
    "    optimizer: optimizer to use for model parameter updates.\n",
    "    criterion: used to compute loss for prediction and target \n",
    "    epoch: Current epoch to train for.\n",
    "    batch_size: Batch size to be used.\n",
    "    '''\n",
    "    \n",
    "    # Set model to train mode before each epoch\n",
    "    model.train()\n",
    "    \n",
    "    # Empty list to store losses \n",
    "    losses = []\n",
    "    correct = 0\n",
    "    # Iterate over entire training samples (1 epoch)\n",
    "    for batch_idx, batch_sample in enumerate(train_loader):\n",
    "        data, target = batch_sample\n",
    "        # print(f'{data.shape = }')\n",
    "        \n",
    "        # Push data/label to correct device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset optimizer gradients. Avoids grad accumulation (accumulation used in RNN).\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Do forward pass for current set of data\n",
    "        output = model(data)\n",
    "        # Compute loss based on criterion\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Computes gradient based on final loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Store loss\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Optimize model parameters based on learning rate and gradient \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Get predicted index by selecting maximum log-probability\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        _, predictions = output.max(1)\n",
    "        correct += (predictions == target).sum()\n",
    "        print(f'Training epoch: ({epoch}/{num_epochs}) batch: ({batch_idx+1}/{len(train_loader)})', end='\\r') #. Acc: {correct}/{(batch_idx+1) * batch_size}, {100. * correct / ((batch_idx+1) * batch_size)}', end='\\r')\n",
    "        \n",
    "    train_loss = float(np.mean(losses))\n",
    "    train_acc = correct / ((batch_idx+1) * batch_size)\n",
    "    print('\\nTrain set ({}/{}): Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(epoch, num_epochs,\n",
    "        float(np.mean(losses)), correct, (batch_idx+1) * batch_size,\n",
    "        100. * correct / ((batch_idx+1) * batch_size)))\n",
    "    return train_loss, train_acc\n",
    "    \n",
    "def test(model, device, test_loader, criterion, epoch, num_epochs, batch_size):\n",
    "    '''\n",
    "    Tests the model.\n",
    "    model: The model to train. Should already be in correct device.\n",
    "    device: 'cuda' or 'cpu'.\n",
    "    test_loader: dataloader for test samples.\n",
    "    '''\n",
    "    \n",
    "    # Set model to eval mode to notify all layers.\n",
    "    model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    correct = 0\n",
    "    \n",
    "    # Set torch.no_grad() to disable gradient computation and backpropagation\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, sample in enumerate(test_loader):\n",
    "            data, target = sample\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Predict for data by doing forward pass\n",
    "            output = model(data)\n",
    "        \n",
    "            # Compute loss based on same criterion as training \n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # Append loss to overall test loss\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Get predicted index by selecting maximum log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            \n",
    "            _, predictions = output.max(1)\n",
    "            correct += (predictions == target).sum()\n",
    "            print(f'Testing epoch: ({epoch}/{num_epochs}) batch: ({batch_idx+1}/{len(test_loader)})', end='\\r')\n",
    "\n",
    "    test_loss = float(np.mean(losses))\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set ({}/{}): Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(epoch, num_epochs,\n",
    "        test_loss, correct, len(test_loader.dataset), accuracy))\n",
    "    \n",
    "    return test_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(mode=1, learning_rate=0.01, batch_size=10, num_epochs=60):\n",
    "    image_size = 28*28\n",
    "    num_classes = 10\n",
    "\n",
    "    # Initialize the model and send to device \n",
    "    model = ConvNet(mode, image_size, num_classes).to(device)\n",
    "    # Define loss function.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Define optimizer function.\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Define data loaders\n",
    "    train_loader, test_loader = load_data(batch_size)\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    # Run training for n_epochs specified in config \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_accuracy = train(model, device, train_loader,\n",
    "                                            optimizer, criterion, epoch, batch_size, num_epochs)\n",
    "        test_loss, test_accuracy = test(model, device, test_loader, criterion, epoch, num_epochs, batch_size)\n",
    "        \n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy.cpu().numpy())\n",
    "\n",
    "    plot(num_epochs, train_losses, train_accuracies, save=1, mode=mode)\n",
    "\n",
    "    print(\"Accuracy: {:2.2f}%\".format(best_accuracy))\n",
    "\n",
    "    print(\"Training and evaluation finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: (1/5) batch: (6000/6000)\n",
      "Train set (1/5): Average loss: 0.6031, Accuracy: 51494/60000 (86%)\n",
      "\n",
      "Testing epoch: (1/5) batch: (1000/1000)\n",
      "Test set (1/5): Average loss: 0.3139, Accuracy: 9132/10000 (91%)\n",
      "\n",
      "Training epoch: (2/5) batch: (6000/6000)\n",
      "Train set (2/5): Average loss: 0.2895, Accuracy: 55125/60000 (92%)\n",
      "\n",
      "Testing epoch: (2/5) batch: (1000/1000)\n",
      "Test set (2/5): Average loss: 0.2535, Accuracy: 9287/10000 (93%)\n",
      "\n",
      "Training epoch: (3/5) batch: (6000/6000)\n",
      "Train set (3/5): Average loss: 0.2411, Accuracy: 55874/60000 (93%)\n",
      "\n",
      "Testing epoch: (3/5) batch: (1000/1000)\n",
      "Test set (3/5): Average loss: 0.2221, Accuracy: 9366/10000 (94%)\n",
      "\n",
      "Training epoch: (4/5) batch: (6000/6000)\n",
      "Train set (4/5): Average loss: 0.2096, Accuracy: 56390/60000 (94%)\n",
      "\n",
      "Testing epoch: (4/5) batch: (1000/1000)\n",
      "Test set (4/5): Average loss: 0.1974, Accuracy: 9424/10000 (94%)\n",
      "\n",
      "Training epoch: (5/5) batch: (6000/6000)\n",
      "Train set (5/5): Average loss: 0.1863, Accuracy: 56845/60000 (95%)\n",
      "\n",
      "Testing epoch: (5/5) batch: (1000/1000)\n",
      "Test set (5/5): Average loss: 0.1808, Accuracy: 9464/10000 (95%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 94.64\n",
      "Training and evaluation finished\n"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "# num_epochs = 60\n",
    "num_epochs = 5\n",
    "\n",
    "run_model(mode=1, learning_rate=learning_rate, batch_size=batch_size, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: (1/5) batch: (6000/6000)\n",
      "Train set (1/5): Average loss: 0.9695, Accuracy: 41520/60000 (69%)\n",
      "\n",
      "Testing epoch: (1/5) batch: (1000/1000)\n",
      "Test set (1/5): Average loss: 0.2948, Accuracy: 9175/10000 (92%)\n",
      "\n",
      "Training epoch: (2/5) batch: (806/6000)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d_/ck6qtb554x7fcmpxs24wxn1w0000gn/T/ipykernel_35595/1708751908.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/d_/ck6qtb554x7fcmpxs24wxn1w0000gn/T/ipykernel_35595/1980768729.py\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(mode, learning_rate, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Run training for n_epochs specified in config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         train_loss, train_accuracy = train(model, device, train_loader,\n\u001b[0m\u001b[1;32m     21\u001b[0m                                             optimizer, criterion, epoch, batch_size, num_epochs)\n\u001b[1;32m     22\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/d_/ck6qtb554x7fcmpxs24wxn1w0000gn/T/ipykernel_35595/831085847.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, criterion, epoch, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Computes gradient based on final loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Store loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 60\n",
    "num_epochs = 5\n",
    "\n",
    "run_model(mode=2, learning_rate=learning_rate, batch_size=batch_size, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: (1/60) batch: (76/6000)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d_/ck6qtb554x7fcmpxs24wxn1w0000gn/T/ipykernel_34734/721879869.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/d_/ck6qtb554x7fcmpxs24wxn1w0000gn/T/ipykernel_34734/2097440890.py\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, learning_rate, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Run training for n_epochs specified in config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         train_loss, train_accuracy = train(model, device, train_loader,\n\u001b[0m\u001b[1;32m     19\u001b[0m                                             optimizer, criterion, epoch, batch_size, num_epochs)\n\u001b[1;32m     20\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/d_/ck6qtb554x7fcmpxs24wxn1w0000gn/T/ipykernel_34734/1536805527.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, criterion, epoch, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Reset optimizer gradients. Avoids grad accumulation (accumulation used in RNN).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Do forward pass for current set of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mforeach\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                                 \u001b[0mper_device_and_dtype_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "learning_rate = 0.03\n",
    "batch_size = 10\n",
    "num_epochs = 60\n",
    "\n",
    "run_model(mode=3, learning_rate=learning_rate, batch_size=batch_size, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: (1/60) batch: (75/6000)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d_/ck6qtb554x7fcmpxs24wxn1w0000gn/T/ipykernel_35595/960330806.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/d_/ck6qtb554x7fcmpxs24wxn1w0000gn/T/ipykernel_35595/2097440890.py\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, learning_rate, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Run training for n_epochs specified in config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         train_loss, train_accuracy = train(model, device, train_loader,\n\u001b[0m\u001b[1;32m     19\u001b[0m                                             optimizer, criterion, epoch, batch_size, num_epochs)\n\u001b[1;32m     20\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/d_/ck6qtb554x7fcmpxs24wxn1w0000gn/T/ipykernel_35595/1536805527.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, criterion, epoch, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Computes gradient based on final loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Store loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model 4\n",
    "learning_rate = 0.03\n",
    "batch_size = 10\n",
    "num_epochs = 60\n",
    "\n",
    "run_model(mode=4, learning_rate=learning_rate, batch_size=batch_size, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: (1/40) batch: (50/6000)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d_/ck6qtb554x7fcmpxs24wxn1w0000gn/T/ipykernel_35446/4194232024.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/d_/ck6qtb554x7fcmpxs24wxn1w0000gn/T/ipykernel_35446/2097440890.py\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, learning_rate, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Run training for n_epochs specified in config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         train_loss, train_accuracy = train(model, device, train_loader,\n\u001b[0m\u001b[1;32m     19\u001b[0m                                             optimizer, criterion, epoch, batch_size, num_epochs)\n\u001b[1;32m     20\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/d_/ck6qtb554x7fcmpxs24wxn1w0000gn/T/ipykernel_35446/1536805527.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, criterion, epoch, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Do forward pass for current set of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Compute loss based on criterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UCF/Fall22/Computer Vision/Assignments/Programming Assignment 2/ConvNet.py\u001b[0m in \u001b[0;36mmodel_5\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    451\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 453\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    454\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model 5\n",
    "learning_rate = 0.03\n",
    "batch_size = 10\n",
    "num_epochs = 40\n",
    "\n",
    "run_model(mode=5, learning_rate=learning_rate, batch_size=batch_size, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
